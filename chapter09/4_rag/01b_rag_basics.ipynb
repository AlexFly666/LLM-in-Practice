{
 "cells": [
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "import os\n",
    "\n",
    "from langchain_community.vectorstores import Chroma\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "\n",
    "# Define the persistent directory\n",
    "current_dir = os.path.dirname(os.path.abspath(__file__))\n",
    "persistent_directory = os.path.join(current_dir, \"db\", \"chroma_db\")\n",
    "\n",
    "# Define the embedding model\n",
    "embeddings = OpenAIEmbeddings(model=\"text-embedding-3-small\")\n",
    "\n",
    "# Load the existing vector store with the embedding function\n",
    "db = Chroma(persist_directory=persistent_directory,\n",
    "            embedding_function=embeddings)\n",
    "\n",
    "# Define the user's question\n",
    "query = \"Who is Odysseus' wife?\"\n",
    "\n",
    "# Retrieve relevant documents based on the query\n",
    "retriever = db.as_retriever(\n",
    "    search_type=\"similarity_score_threshold\",\n",
    "    search_kwargs={\"k\": 3, \"score_threshold\": 0.9},\n",
    ")\n",
    "relevant_docs = retriever.invoke(query)\n",
    "\n",
    "# Display the relevant results with metadata\n",
    "print(\"\\n--- Relevant Documents ---\")\n",
    "for i, doc in enumerate(relevant_docs, 1):\n",
    "    print(f\"Document {i}:\\n{doc.page_content}\\n\")\n",
    "    if doc.metadata:\n",
    "        print(f\"Source: {doc.metadata.get('source', 'Unknown')}\\n\")\n"
   ],
   "id": "3c5613e1e6c914dc"
  }
 ],
 "metadata": {},
 "nbformat": 5,
 "nbformat_minor": 9
}
