{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AlexFly666/LLM-in-Practice/blob/main/chapter09/0_quikstart/langchain_agent_search.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "initial_id",
      "metadata": {
        "collapsed": true,
        "id": "initial_id",
        "outputId": "7f1bffda-72a1-421b-c30d-ba79c8f71ce3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting langchain-community\n",
            "  Downloading langchain_community-0.3.17-py3-none-any.whl.metadata (2.4 kB)\n",
            "Collecting langgraph\n",
            "  Downloading langgraph-0.2.70-py3-none-any.whl.metadata (17 kB)\n",
            "Collecting langchain-openai\n",
            "  Downloading langchain_openai-0.3.4-py3-none-any.whl.metadata (2.3 kB)\n",
            "Collecting tavily-python\n",
            "  Downloading tavily_python-0.5.1-py3-none-any.whl.metadata (91 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m91.0/91.0 kB\u001b[0m \u001b[31m6.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting langgraph-checkpoint-sqlite\n",
            "  Downloading langgraph_checkpoint_sqlite-2.0.3-py3-none-any.whl.metadata (3.0 kB)\n",
            "Collecting langchain-core<1.0.0,>=0.3.34 (from langchain-community)\n",
            "  Downloading langchain_core-0.3.34-py3-none-any.whl.metadata (5.9 kB)\n",
            "Collecting langchain<1.0.0,>=0.3.18 (from langchain-community)\n",
            "  Downloading langchain-0.3.18-py3-none-any.whl.metadata (7.8 kB)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (2.0.37)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (2.32.3)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (6.0.2)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (3.11.11)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10,>=8.1.0 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (9.0.0)\n",
            "Collecting dataclasses-json<0.7,>=0.5.7 (from langchain-community)\n",
            "  Downloading dataclasses_json-0.6.7-py3-none-any.whl.metadata (25 kB)\n",
            "Collecting pydantic-settings<3.0.0,>=2.4.0 (from langchain-community)\n",
            "  Downloading pydantic_settings-2.7.1-py3-none-any.whl.metadata (3.5 kB)\n",
            "Requirement already satisfied: langsmith<0.4,>=0.1.125 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (0.3.5)\n",
            "Collecting httpx-sse<1.0.0,>=0.4.0 (from langchain-community)\n",
            "  Downloading httpx_sse-0.4.0-py3-none-any.whl.metadata (9.0 kB)\n",
            "Requirement already satisfied: numpy<2,>=1.26.4 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (1.26.4)\n",
            "Collecting langgraph-checkpoint<3.0.0,>=2.0.10 (from langgraph)\n",
            "  Downloading langgraph_checkpoint-2.0.12-py3-none-any.whl.metadata (4.6 kB)\n",
            "Collecting langgraph-sdk<0.2.0,>=0.1.42 (from langgraph)\n",
            "  Downloading langgraph_sdk-0.1.51-py3-none-any.whl.metadata (1.8 kB)\n",
            "Requirement already satisfied: openai<2.0.0,>=1.58.1 in /usr/local/lib/python3.11/dist-packages (from langchain-openai) (1.61.1)\n",
            "Collecting tiktoken<1,>=0.7 (from langchain-openai)\n",
            "  Downloading tiktoken-0.8.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.6 kB)\n",
            "Requirement already satisfied: httpx in /usr/local/lib/python3.11/dist-packages (from tavily-python) (0.28.1)\n",
            "Collecting aiosqlite<0.21.0,>=0.20.0 (from langgraph-checkpoint-sqlite)\n",
            "  Downloading aiosqlite-0.20.0-py3-none-any.whl.metadata (4.3 kB)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (2.4.4)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (25.1.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (6.1.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (0.2.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.18.3)\n",
            "Requirement already satisfied: typing_extensions>=4.0 in /usr/local/lib/python3.11/dist-packages (from aiosqlite<0.21.0,>=0.20.0->langgraph-checkpoint-sqlite) (4.12.2)\n",
            "Collecting marshmallow<4.0.0,>=3.18.0 (from dataclasses-json<0.7,>=0.5.7->langchain-community)\n",
            "  Downloading marshmallow-3.26.1-py3-none-any.whl.metadata (7.3 kB)\n",
            "Collecting typing-inspect<1,>=0.4.0 (from dataclasses-json<0.7,>=0.5.7->langchain-community)\n",
            "  Downloading typing_inspect-0.9.0-py3-none-any.whl.metadata (1.5 kB)\n",
            "Collecting langchain-text-splitters<1.0.0,>=0.3.6 (from langchain<1.0.0,>=0.3.18->langchain-community)\n",
            "  Downloading langchain_text_splitters-0.3.6-py3-none-any.whl.metadata (1.9 kB)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in /usr/local/lib/python3.11/dist-packages (from langchain<1.0.0,>=0.3.18->langchain-community) (2.10.6)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.34->langchain-community) (1.33)\n",
            "Requirement already satisfied: packaging<25,>=23.2 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.34->langchain-community) (24.2)\n",
            "Requirement already satisfied: msgpack<2.0.0,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from langgraph-checkpoint<3.0.0,>=2.0.10->langgraph) (1.1.0)\n",
            "Requirement already satisfied: orjson>=3.10.1 in /usr/local/lib/python3.11/dist-packages (from langgraph-sdk<0.2.0,>=0.1.42->langgraph) (3.10.15)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.11/dist-packages (from httpx->tavily-python) (3.7.1)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx->tavily-python) (2025.1.31)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx->tavily-python) (1.0.7)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.11/dist-packages (from httpx->tavily-python) (3.10)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx->tavily-python) (0.14.0)\n",
            "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.125->langchain-community) (1.0.0)\n",
            "Requirement already satisfied: zstandard<0.24.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.125->langchain-community) (0.23.0)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.11/dist-packages (from openai<2.0.0,>=1.58.1->langchain-openai) (1.9.0)\n",
            "Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from openai<2.0.0,>=1.58.1->langchain-openai) (0.8.2)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.11/dist-packages (from openai<2.0.0,>=1.58.1->langchain-openai) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.11/dist-packages (from openai<2.0.0,>=1.58.1->langchain-openai) (4.67.1)\n",
            "Collecting python-dotenv>=0.21.0 (from pydantic-settings<3.0.0,>=2.4.0->langchain-community)\n",
            "  Downloading python_dotenv-1.0.1-py3-none-any.whl.metadata (23 kB)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain-community) (3.4.1)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain-community) (2.3.0)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.11/dist-packages (from SQLAlchemy<3,>=1.4->langchain-community) (3.1.1)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.11/dist-packages (from tiktoken<1,>=0.7->langchain-openai) (2024.11.6)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.11/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<1.0.0,>=0.3.34->langchain-community) (3.0.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain<1.0.0,>=0.3.18->langchain-community) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.27.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain<1.0.0,>=0.3.18->langchain-community) (2.27.2)\n",
            "Collecting mypy-extensions>=0.3.0 (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain-community)\n",
            "  Downloading mypy_extensions-1.0.0-py3-none-any.whl.metadata (1.1 kB)\n",
            "Downloading langchain_community-0.3.17-py3-none-any.whl (2.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.5/2.5 MB\u001b[0m \u001b[31m62.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading langgraph-0.2.70-py3-none-any.whl (149 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m149.7/149.7 kB\u001b[0m \u001b[31m12.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading langchain_openai-0.3.4-py3-none-any.whl (54 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m54.7/54.7 kB\u001b[0m \u001b[31m4.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tavily_python-0.5.1-py3-none-any.whl (43 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.8/43.8 kB\u001b[0m \u001b[31m3.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading langgraph_checkpoint_sqlite-2.0.3-py3-none-any.whl (12 kB)\n",
            "Downloading aiosqlite-0.20.0-py3-none-any.whl (15 kB)\n",
            "Downloading dataclasses_json-0.6.7-py3-none-any.whl (28 kB)\n",
            "Downloading httpx_sse-0.4.0-py3-none-any.whl (7.8 kB)\n",
            "Downloading langchain-0.3.18-py3-none-any.whl (1.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m53.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading langchain_core-0.3.34-py3-none-any.whl (412 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m413.0/413.0 kB\u001b[0m \u001b[31m30.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading langgraph_checkpoint-2.0.12-py3-none-any.whl (38 kB)\n",
            "Downloading langgraph_sdk-0.1.51-py3-none-any.whl (44 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.7/44.7 kB\u001b[0m \u001b[31m3.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pydantic_settings-2.7.1-py3-none-any.whl (29 kB)\n",
            "Downloading tiktoken-0.8.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m54.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading langchain_text_splitters-0.3.6-py3-none-any.whl (31 kB)\n",
            "Downloading marshmallow-3.26.1-py3-none-any.whl (50 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.9/50.9 kB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading python_dotenv-1.0.1-py3-none-any.whl (19 kB)\n",
            "Downloading typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n",
            "Downloading mypy_extensions-1.0.0-py3-none-any.whl (4.7 kB)\n",
            "Installing collected packages: python-dotenv, mypy-extensions, marshmallow, httpx-sse, aiosqlite, typing-inspect, tiktoken, tavily-python, pydantic-settings, langgraph-sdk, dataclasses-json, langchain-core, langgraph-checkpoint, langchain-text-splitters, langchain-openai, langgraph-checkpoint-sqlite, langgraph, langchain, langchain-community\n",
            "  Attempting uninstall: langchain-core\n",
            "    Found existing installation: langchain-core 0.3.33\n",
            "    Uninstalling langchain-core-0.3.33:\n",
            "      Successfully uninstalled langchain-core-0.3.33\n",
            "  Attempting uninstall: langchain-text-splitters\n",
            "    Found existing installation: langchain-text-splitters 0.3.5\n",
            "    Uninstalling langchain-text-splitters-0.3.5:\n",
            "      Successfully uninstalled langchain-text-splitters-0.3.5\n",
            "  Attempting uninstall: langchain\n",
            "    Found existing installation: langchain 0.3.17\n",
            "    Uninstalling langchain-0.3.17:\n",
            "      Successfully uninstalled langchain-0.3.17\n",
            "Successfully installed aiosqlite-0.20.0 dataclasses-json-0.6.7 httpx-sse-0.4.0 langchain-0.3.18 langchain-community-0.3.17 langchain-core-0.3.34 langchain-openai-0.3.4 langchain-text-splitters-0.3.6 langgraph-0.2.70 langgraph-checkpoint-2.0.12 langgraph-checkpoint-sqlite-2.0.3 langgraph-sdk-0.1.51 marshmallow-3.26.1 mypy-extensions-1.0.0 pydantic-settings-2.7.1 python-dotenv-1.0.1 tavily-python-0.5.1 tiktoken-0.8.0 typing-inspect-0.9.0\n"
          ]
        }
      ],
      "source": [
        "# LangChain V0.3版本\n",
        "!pip install langchain-community \\\n",
        "        langgraph \\\n",
        "        langchain-openai \\\n",
        "        tavily-python \\\n",
        "        langgraph-checkpoint-sqlite"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 将使用Tavily（搜索引擎）作为工具。要使用它，你需要获取并设置API密钥：\n",
        "# Tavily's Search API地址 https://tavily.com/\n",
        "import os\n",
        "os.environ[\"TAVILY_API_KEY\"] = \"XXX\" # 将 API key 设置为环境变量\n"
      ],
      "metadata": {
        "id": "GbTACLEu4LeF"
      },
      "id": "GbTACLEu4LeF",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Ng9gnPYEu-RI"
      },
      "id": "Ng9gnPYEu-RI",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "id": "45cb94e4b83b9b37"
      },
      "cell_type": "code",
      "outputs": [],
      "execution_count": null,
      "source": [
        "# 导入相关的 LangChain 功能模块\n",
        "# 从 langchain_openai 库导入 ChatOpenAI 和 OpenAIEmbeddings，用于使用 OpenAI 的聊天模型和嵌入模型\n",
        "from langchain_openai import ChatOpenAI\n",
        "from langchain_community.tools.tavily_search import TavilySearchResults  # 导入 Tavily 搜索引擎工具\n",
        "from langchain_core.messages import HumanMessage  # 导入 HumanMessage 类型，用于表示用户输入\n",
        "from langgraph.checkpoint.memory import MemorySaver  # 导入 MemorySaver，用于内存存储对话历史\n",
        "from langgraph.prebuilt import create_react_agent  # 导入 create_react_agent 函数，用于创建 React Agent"
      ],
      "id": "45cb94e4b83b9b37"
    },
    {
      "metadata": {
        "id": "7adc49e0c73e9bf4",
        "outputId": "0bbc50cb-d661-49b8-c15b-352ae221b6b4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "cell_type": "code",
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- 首次对话 ---\n",
            "{'agent': {'messages': [AIMessage(content='你好，小明！很高兴认识你。北京是个充满历史和文化的地方，你最喜欢那里哪个景点呢？', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 50, 'prompt_tokens': 93, 'total_tokens': 143, 'completion_tokens_details': None, 'prompt_tokens_details': None}, 'model_name': 'gpt-3.5-turbo', 'system_fingerprint': None, 'finish_reason': 'stop', 'logprobs': None}, id='run-5f9a334b-e46c-4afc-bebd-f1db22860bb9-0', usage_metadata={'input_tokens': 93, 'output_tokens': 50, 'total_tokens': 143, 'input_token_details': {}, 'output_token_details': {}})]}}\n",
            "----\n",
            "\n",
            "--- 第二次对话 ---\n",
            "{'agent': {'messages': [AIMessage(content='我无法提供实时天气信息，但你可以通过天气应用或网站查询北京的最新天气情况。一般来说，北京冬季寒冷干燥，夏季炎热潮湿。你今天打算出去吗？', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 83, 'prompt_tokens': 165, 'total_tokens': 248, 'completion_tokens_details': None, 'prompt_tokens_details': None}, 'model_name': 'gpt-3.5-turbo', 'system_fingerprint': None, 'finish_reason': 'stop', 'logprobs': None}, id='run-2a6b654a-4e1a-4663-b916-25cb8f5bf1af-0', usage_metadata={'input_tokens': 165, 'output_tokens': 83, 'total_tokens': 248, 'input_token_details': {}, 'output_token_details': {}})]}}\n",
            "----\n",
            "\n",
            "--- 第三次对话 (验证记忆) ---\n",
            "{'agent': {'messages': [AIMessage(content='你叫小明。有什么我可以帮助你的吗？', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 21, 'prompt_tokens': 267, 'total_tokens': 288, 'completion_tokens_details': None, 'prompt_tokens_details': None}, 'model_name': 'gpt-3.5-turbo', 'system_fingerprint': None, 'finish_reason': 'stop', 'logprobs': None}, id='run-96ebcfb8-5ff7-41c3-932f-aedf55ec069d-0', usage_metadata={'input_tokens': 267, 'output_tokens': 21, 'total_tokens': 288, 'input_token_details': {}, 'output_token_details': {}})]}}\n",
            "----\n",
            "\n",
            "--- 新的对话 (无记忆) ---\n",
            "{'agent': {'messages': [AIMessage(content='抱歉，我无法知道您的名字。您可以告诉我您想让我如何称呼您吗？', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 36, 'prompt_tokens': 88, 'total_tokens': 124, 'completion_tokens_details': None, 'prompt_tokens_details': None}, 'model_name': 'gpt-3.5-turbo', 'system_fingerprint': None, 'finish_reason': 'stop', 'logprobs': None}, id='run-a87defdf-f6b5-48db-ab78-27fe51caaa38-0', usage_metadata={'input_tokens': 88, 'output_tokens': 36, 'total_tokens': 124, 'input_token_details': {}, 'output_token_details': {}})]}}\n",
            "----\n",
            "\n",
            "---  代码执行完成  ---\n"
          ]
        }
      ],
      "execution_count": null,
      "source": [
        "# 创建 Agent 的组件\n",
        "\n",
        "# 初始化内存存储器，用于保存对话历史 (可选，用于有状态 Agent)\n",
        "memory = MemorySaver()\n",
        "\n",
        "# Create a ChatOpenAI model\n",
        "# OpenAI API调用（代理方式）\n",
        "model = ChatOpenAI(\n",
        "    api_key=\"XXX\",\n",
        "    base_url=\"https://vip.apiyi.com/v1\"\n",
        ")\n",
        "\n",
        "\n",
        "# 初始化 Tavily 搜索引擎工具，设置最大搜索结果数为 2\n",
        "search = TavilySearchResults(max_results=2)\n",
        "# 将 Tavily 搜索引擎工具放入工具列表，Agent 可以使用这些工具\n",
        "tools = [search]\n",
        "\n",
        "# 使用 `create_react_agent` 函数创建 Agent 执行器\n",
        "# 该函数会自动将模型和工具绑定，并使用 ReAct 框架构建 Agent\n",
        "# checkpointer=memory 参数用于启用对话记忆功能\n",
        "agent_executor = create_react_agent(model, tools, checkpointer=memory)\n",
        "\n",
        "\n",
        "# ---  首次对话：打招呼并告知所在地 ---\n",
        "# 配置对话线程 ID，用于记忆功能，相同 thread_id 共享对话历史\n",
        "config = {\"configurable\": {\"thread_id\": \"abc123\"}}\n",
        "print(\"--- 首次对话 ---\")\n",
        "# 使用 stream 方法进行流式输出，逐步显示 Agent 的响应\n",
        "for chunk in agent_executor.stream(\n",
        "    # 构造用户输入消息 HumanMessage -  用户用中文打招呼，并告知住在北京\n",
        "    {\"messages\": [HumanMessage(content=\"你好！我是小明，我住在北京。\")]}, config\n",
        "):\n",
        "    # 打印每个 chunk 的输出，展示 Agent 的思考过程\n",
        "    print(chunk)\n",
        "    print(\"----\")\n",
        "\n",
        "\n",
        "# ---  第二次对话：询问天气 ---\n",
        "print(\"\\n--- 第二次对话 ---\")\n",
        "for chunk in agent_executor.stream(\n",
        "    # 再次使用相同的 thread_id，Agent 将记住之前的对话 -  用户用中文询问天气\n",
        "    {\"messages\": [HumanMessage(content=\"我住的地方天气怎么样？\")]}, config\n",
        "):\n",
        "    print(chunk)\n",
        "    print(\"----\")\n",
        "\n",
        "\n",
        "# ---  第三次对话： 询问名字 ---\n",
        "print(\"\\n--- 第三次对话 (验证记忆) ---\")\n",
        "for chunk in agent_executor.stream(\n",
        "    # 继续使用相同的 thread_id -  用户用中文询问名字\n",
        "    {\"messages\": [HumanMessage(content=\"请问我叫什么名字？\")]}, config\n",
        "):\n",
        "    print(chunk)\n",
        "    print(\"----\")\n",
        "\n",
        "\n",
        "# ---  新的对话：更换线程 ID，验证无记忆 ---\n",
        "# 使用新的 thread_id，开启新的对话\n",
        "config_new_thread = {\"configurable\": {\"thread_id\": \"xyz123\"}}\n",
        "print(\"\\n--- 新的对话 (无记忆) ---\")\n",
        "for chunk in agent_executor.stream(\n",
        "    # 用户在新对话线程中，用中文询问名字\n",
        "    {\"messages\": [HumanMessage(content=\"我叫什么名字？\")]}, config_new_thread\n",
        "):\n",
        "    print(chunk)\n",
        "    print(\"----\")\n",
        "\n",
        "\n",
        "print(\"\\n---  代码执行完成  ---\")"
      ],
      "id": "7adc49e0c73e9bf4"
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -qU \"langchain-community>=0.2.11\" tavily-python"
      ],
      "metadata": {
        "id": "H6eM8QYaylPa",
        "outputId": "7dca7b50-a850-42df-93a2-a7941ce3d843",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "H6eM8QYaylPa",
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m91.0/91.0 kB\u001b[0m \u001b[31m1.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.5/2.5 MB\u001b[0m \u001b[31m25.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.8/43.8 kB\u001b[0m \u001b[31m1.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m19.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m413.0/413.0 kB\u001b[0m \u001b[31m11.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m21.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.9/50.9 kB\u001b[0m \u001b[31m1.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 将使用Tavily（搜索引擎）作为工具。要使用它，你需要获取并设置API密钥：\n",
        "# Tavily's Search API地址 https://tavily.com/\n",
        "import os\n",
        "os.environ[\"TAVILY_API_KEY\"] = \"XXX\" # 将 API key 设置为环境变量"
      ],
      "metadata": {
        "id": "pherxyPtyrDw"
      },
      "id": "pherxyPtyrDw",
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 展示如何实例化 Tavily 搜索工具，使用\n",
        "from langchain_community.tools import TavilySearchResults\n",
        "\n",
        "tool = TavilySearchResults(\n",
        "    max_results=5,\n",
        "    search_depth=\"advanced\",\n",
        "    include_answer=True,\n",
        "    include_raw_content=True,\n",
        "    include_images=True,\n",
        "    # include_domains=[...],\n",
        "    # exclude_domains=[...],\n",
        "    # name=\"...\",            # overwrite default tool name\n",
        "    # description=\"...\",     # overwrite default tool description\n",
        "    # args_schema=...,       # overwrite default args_schema: BaseModel\n",
        ")"
      ],
      "metadata": {
        "id": "OPSJ3u4Oy3xw"
      },
      "id": "OPSJ3u4Oy3xw",
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 查询\n",
        "tool.invoke({\"query\": \"What happened at the last wimbledon\"})"
      ],
      "metadata": {
        "id": "8rvjifU7y8AA",
        "outputId": "ccb0c7a7-8e52-47d8-ebbf-ae8ca7376d6e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "8rvjifU7y8AA",
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'url': 'https://www.nbcnews.com/news/sports/andy-murray-wimbledon-tennis-singles-draw-rcna159912',\n",
              "  'content': \"NBC News Now LONDON — Andy Murray, one of the last decade's most successful male tennis players, has pulled out of the singles tournament at what is almost certain to be his last Wimbledon, his team confirmed Tuesday. Murray, 37, who has won the Wimbledon singles title twice and the U.S Open once, has been battling to be fit to play at the All England Club for weeks. “Unfortunately, despite working incredibly hard on his recovery since his operation just over a week ago, Andy has taken the very difficult decision not to play the singles this year,” his team said in a statement reported by Sky News. The news caps a glittering career on the ATP singles tour, which placed Murray at No. 1 in the world for 41 weeks.\"},\n",
              " {'url': 'https://www.nytimes.com/athletic/live-blogs/wimbledon-2024-live-updates-alcaraz-djokovic-mens-final-result/kJJdTKhOgkZo/mGpXBR2QIift/',\n",
              "  'content': \"Carlos Alcaraz beats Novak Djokovic to win the men's singles final In the 2023 final, Carlos Alcaraz won his first Wimbledon title, and only his second Grand Slam title, after beating Novak Djokovic in a five-set thriller on Centre Court. GO FURTHER Novak Djokovic and Carlos Alcaraz’s Wimbledon final is a duel of extraordinary quests Novak Djokovic set up a Wimbledon rematch with Carlos Alcaraz by beating Lorenzo Musetti, 6-4, 7-6, 6-3 on Centre Court on Friday, concluding his run to the final at the All England Club that started just 25 days after surgery on a torn meniscus in his right knee. GO FURTHER Novak Djokovic beats Lorenzo Musetti for Wimbledon final against Carlos Alcaraz\"},\n",
              " {'url': 'https://www.bbc.com/sport/tennis/articles/cxe2x31ez8vo',\n",
              "  'content': 'Wimbledon men\\'s final: Novak Djokovic says \\'history will be on the line\\' against Carlos Alcaraz - BBC Sport Novak Djokovic is hoping to avenge his loss to Carlos Alcaraz in last year\\'s Wimbledon final Novak Djokovic says \"history will be on the line\" when he faces Carlos Alcaraz in the Wimbledon men\\'s singles final. Wimbledon crowd boos as Novak Djokovic performs a violin celebration after his semi-final win The third seed, who has won 13 consecutive matches at Wimbledon, had the support of most of the crowd during last year\\'s final, although he may be pushing his luck by jokingly poking fun at England supporters this week before his nation\\'s Euro 2024 final with the Three Lions.'},\n",
              " {'url': 'https://www.nytimes.com/athletic/live-blogs/wimbledon-2024-live-updates-day-two-murray-djokovic-scores-results/bVuQoHpnfnrg/EPsBusvPvmqH/',\n",
              "  'content': \"Follow live reaction of the second day at Wimbledon 2024 as Britain's Jack Draper progresses after compatriot Andy Murray withdraws amid rain delays There was one result wrapped up before play was suspended: American Jessica Pegula, the fifth seed, absolutely raced through her match against compatriot Ashlyn Krueger, winning 6-2, 6-0 on Court 2. What do tennis players do at Wimbledon when rain stops play? GO FURTHER What do tennis players do at Wimbledon when rain stops play? GO FURTHER Andy Murray Wimbledon tribute: How his tennis and his titles played with our hearts Murray's fellow Brit Jack Draper, the man tipped by some to step into the Scot's shoes as the prime figure in British tennis, is now the third match on Centre Court.\"},\n",
              " {'url': 'https://www.wimbledon.com/en_GB/news/articles/2023-07-16/alcaraz_ends_the_djokovic_run.html',\n",
              "  'content': \"A game within a match to win a Championship: Carlos Alcaraz won it and Novak Djokovic didn't and so it is that the 20-year-old world No.1 is the new Wimbledon champion. Alcaraz won 1-6, 7-6(6), 6-1, 3-6, 6-4. Djokovic was, as usual, chasing history. He was attempting to become only the third man in the Open era to win five consecutive Wimbledon titles and only the second to win eight in all.\"}]"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 实战"
      ],
      "metadata": {
        "id": "OdfyKS6903q4"
      },
      "id": "OdfyKS6903q4"
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -qU \"langchain[openai]>=0.2.11\" tavily-python langchain"
      ],
      "metadata": {
        "id": "oyEiXj_Rzh8n",
        "outputId": "923c74da-da93-44de-8c50-3fbd4d6a6727",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "oyEiXj_Rzh8n",
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/54.7 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m54.7/54.7 kB\u001b[0m \u001b[31m1.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 将使用Tavily（搜索引擎）作为工具。要使用它，你需要获取并设置API密钥：\n",
        "# Tavily's Search API地址 https://tavily.com/\n",
        "import os\n",
        "os.environ[\"TAVILY_API_KEY\"] = \"XXX\" # 将 API key 设置为环境变量"
      ],
      "metadata": {
        "id": "fLM_tfLn3qkC"
      },
      "id": "fLM_tfLn3qkC",
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# -*- coding: utf-8 -*-\n",
        "\"\"\"\n",
        "LangChain智能体系统实现 - 温网赛事分析\n",
        "\n",
        "执行流程：\n",
        "1. 安装依赖\n",
        "2. 配置API密钥\n",
        "3. 初始化搜索工具\n",
        "4. 构建智能体系统\n",
        "5. 执行查询分析\n",
        "\"\"\"\n",
        "\n",
        "# === 依赖安装提示 ===\n",
        "\"\"\"\n",
        "# 执行前需先安装依赖（取消注释运行）\n",
        "# pip install -qU \"langchain[openai]>=0.2.11\" tavily-python langchain\n",
        "\"\"\"\n",
        "\n",
        "# === 依赖导入 ===\n",
        "from datetime import datetime\n",
        "import getpass\n",
        "import os\n",
        "from langchain_core.prompts import ChatPromptTemplate\n",
        "from langchain_openai import ChatOpenAI\n",
        "from langchain.agents import AgentExecutor, initialize_agent, AgentType\n",
        "from langchain_community.tools import TavilySearchResults\n",
        "\n",
        "# === 模块定义 ===\n",
        "def configure_environment():\n",
        "    \"\"\"配置API密钥环境变量\"\"\"\n",
        "    if not os.environ.get(\"TAVILY_API_KEY\"):\n",
        "        os.environ[\"TAVILY_API_KEY\"] = getpass.getpass(\"Tavily API key:\\n\")\n",
        "\n",
        "    # 如需使用OpenAI官方接口，取消以下注释\n",
        "    # if not os.environ.get(\"OPENAI_API_KEY\"):\n",
        "    #     os.environ[\"OPENAI_API_KEY\"] = getpass.getpass(\"OpenAI API key:\\n\")\n",
        "\n",
        "def initialize_tools():\n",
        "    \"\"\"初始化搜索工具\"\"\"\n",
        "    return TavilySearchResults(\n",
        "        max_results=3,\n",
        "        search_depth=\"advanced\",\n",
        "        include_answer=True,\n",
        "        include_images=True\n",
        "    )\n",
        "\n",
        "def build_llm():\n",
        "    \"\"\"构建大语言模型实例\"\"\"\n",
        "    return ChatOpenAI(\n",
        "        model=\"gpt-4o-mini\",\n",
        "        temperature=0\n",
        "    )\n",
        "\n",
        "def create_agent(tools, llm):\n",
        "    \"\"\"构建智能体系统\"\"\"\n",
        "    prompt_template = ChatPromptTemplate.from_messages([\n",
        "        (\"system\", \"你是一个专业体育赛事分析师，当前日期：{date}\"),\n",
        "        (\"user\", \"{input}\"),\n",
        "        (\"placeholder\", \"{agent_scratchpad}\")\n",
        "    ])\n",
        "\n",
        "    return initialize_agent(\n",
        "        tools=tools,\n",
        "        llm=llm,\n",
        "        agent=AgentType.OPENAI_FUNCTIONS,\n",
        "        verbose=True,\n",
        "        prompt=prompt_template\n",
        "    )\n",
        "\n",
        "def execute_query(agent_executor, query):\n",
        "    \"\"\"执行分析查询\"\"\"\n",
        "    return agent_executor.invoke({\n",
        "        \"input\": query,\n",
        "        \"date\": datetime.now().strftime(\"%Y-%m-%d\")\n",
        "    })\n",
        "\n",
        "# === 主程序 ===\n",
        "def main():\n",
        "    # 环境配置\n",
        "    configure_environment()\n",
        "\n",
        "    # 组件初始化\n",
        "    search_tool = initialize_tools()\n",
        "    llm_instance = build_llm()\n",
        "    agent = create_agent([search_tool], llm_instance)\n",
        "\n",
        "    # 执行查询\n",
        "    query = \"分析温网女单最新赛事结果及其对选手排名的影响\"\n",
        "    result = execute_query(agent, query)\n",
        "\n",
        "    # 输出结果\n",
        "    print(\"\\n=== 分析报告 ===\")\n",
        "    print(result[\"output\"])\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ],
      "metadata": {
        "id": "R7mPNN0l86fc",
        "outputId": "0e5b5d15-06b7-4a17-9f68-f0c72a1b88a8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "R7mPNN0l86fc",
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
            "\u001b[32;1m\u001b[1;3m\n",
            "Invoking: `tavily_search_results_json` with `{'query': '温网女单最新赛事结果 2023'}`\n",
            "\n",
            "\n",
            "\u001b[0m\u001b[36;1m\u001b[1;3m[{'url': 'https://sports.cctv.com/2023/07/15/VIDEku8DhC6oKpAzxG2RtlUU230715.shtml', 'content': '来源：央视网 更新时间：2023年07月15日 22:54 视频简介 央视网消息：北京时间7月15日，温网女单决赛展开争夺，万卓索娃2-0击败贾巴尔，夺得温网女单冠军。'}, {'url': 'https://sports.cctv.com/2023/07/16/ARTIeKtyW40OwwiUBU38yrGI230716.shtml', 'content': '央视网消息：北京时间7月15日，2023年温网女单决赛，上届亚军、6号种子贾巴尔对阵非种子选手万卓索娃。 万卓索娃直落两盘总分2-0横扫贾巴尔，勇夺温网女单冠军，也是生涯首次夺得大满贯女单冠军，成功缔造一系列纪录创造历史。'}, {'url': 'https://sports.sina.com.cn/tennis/wta/2023-07-16/doc-imzavrzx3251356.shtml', 'content': '北京时间7月16日凌晨，2023温网公开赛结束了第13比赛日的争夺。在女单决赛中，捷克非种子选手万卓索娃一黑到底，以2个6-4横扫6号种子、去年赛会'}]\u001b[0m\u001b[32;1m\u001b[1;3m在2023年温布尔登网球锦标赛（温网）女单决赛中，捷克选手万卓索娃以2-0战胜了6号种子贾巴尔，成功夺得冠军。这是万卓索娃职业生涯中的首个大满贯女单冠军，同时她的胜利也创造了一系列历史纪录。\n",
            "\n",
            "### 赛事结果分析\n",
            "- **决赛结果**：万卓索娃以6-4, 6-4的比分击败贾巴尔。\n",
            "- **选手背景**：万卓索娃在本次比赛中并未被列为种子选手，而贾巴尔是上届亚军和6号种子。\n",
            "\n",
            "### 对选手排名的影响\n",
            "万卓索娃的胜利将显著提升她在WTA（女子网球协会）的排名。根据WTA的积分系统，夺得大满贯赛事的冠军将为选手带来大量积分，这将直接影响她的世界排名。\n",
            "\n",
            "- **万卓索娃的排名提升**：她的冠军积分将使她的排名大幅上升，可能进入前十名。\n",
            "- **贾巴尔的排名变化**：尽管贾巴尔在决赛中失利，但作为6号种子，她仍将保留一定的积分，可能会在排名上有所波动，但不会大幅下降。\n",
            "\n",
            "### 总结\n",
            "万卓索娃的胜利不仅为她的职业生涯增添了辉煌的一笔，也对WTA排名产生了重要影响。随着新赛季的进行，选手们的排名将继续受到后续赛事的影响。\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n",
            "\n",
            "=== 分析报告 ===\n",
            "在2023年温布尔登网球锦标赛（温网）女单决赛中，捷克选手万卓索娃以2-0战胜了6号种子贾巴尔，成功夺得冠军。这是万卓索娃职业生涯中的首个大满贯女单冠军，同时她的胜利也创造了一系列历史纪录。\n",
            "\n",
            "### 赛事结果分析\n",
            "- **决赛结果**：万卓索娃以6-4, 6-4的比分击败贾巴尔。\n",
            "- **选手背景**：万卓索娃在本次比赛中并未被列为种子选手，而贾巴尔是上届亚军和6号种子。\n",
            "\n",
            "### 对选手排名的影响\n",
            "万卓索娃的胜利将显著提升她在WTA（女子网球协会）的排名。根据WTA的积分系统，夺得大满贯赛事的冠军将为选手带来大量积分，这将直接影响她的世界排名。\n",
            "\n",
            "- **万卓索娃的排名提升**：她的冠军积分将使她的排名大幅上升，可能进入前十名。\n",
            "- **贾巴尔的排名变化**：尽管贾巴尔在决赛中失利，但作为6号种子，她仍将保留一定的积分，可能会在排名上有所波动，但不会大幅下降。\n",
            "\n",
            "### 总结\n",
            "万卓索娃的胜利不仅为她的职业生涯增添了辉煌的一笔，也对WTA排名产生了重要影响。随着新赛季的进行，选手们的排名将继续受到后续赛事的影响。\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 2
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython2",
      "version": "2.7.6"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}