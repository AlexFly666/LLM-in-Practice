{
 "cells": [
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "from dotenv import load_dotenv\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "from langchain.schema.output_parser import StrOutputParser\n",
    "from langchain.schema.runnable import RunnableParallel, RunnableLambda\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "# Load environment variables from .env\n",
    "load_dotenv()\n",
    "\n",
    "# Create a ChatOpenAI model\n",
    "model = ChatOpenAI(model=\"gpt-4o\")\n",
    "\n",
    "# Define prompt template\n",
    "prompt_template = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", \"You are an expert product reviewer.\"),\n",
    "        (\"human\", \"List the main features of the product {product_name}.\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "\n",
    "# Define pros analysis step\n",
    "def analyze_pros(features):\n",
    "    pros_template = ChatPromptTemplate.from_messages(\n",
    "        [\n",
    "            (\"system\", \"You are an expert product reviewer.\"),\n",
    "            (\n",
    "                \"human\",\n",
    "                \"Given these features: {features}, list the pros of these features.\",\n",
    "            ),\n",
    "        ]\n",
    "    )\n",
    "    return pros_template.format_prompt(features=features)\n",
    "\n",
    "\n",
    "# Define cons analysis step\n",
    "def analyze_cons(features):\n",
    "    cons_template = ChatPromptTemplate.from_messages(\n",
    "        [\n",
    "            (\"system\", \"You are an expert product reviewer.\"),\n",
    "            (\n",
    "                \"human\",\n",
    "                \"Given these features: {features}, list the cons of these features.\",\n",
    "            ),\n",
    "        ]\n",
    "    )\n",
    "    return cons_template.format_prompt(features=features)\n",
    "\n",
    "\n",
    "# Combine pros and cons into a final review\n",
    "def combine_pros_cons(pros, cons):\n",
    "    return f\"Pros:\\n{pros}\\n\\nCons:\\n{cons}\"\n",
    "\n",
    "\n",
    "# Simplify branches with LCEL\n",
    "pros_branch_chain = (\n",
    "    RunnableLambda(lambda x: analyze_pros(x)) | model | StrOutputParser()\n",
    ")\n",
    "\n",
    "cons_branch_chain = (\n",
    "    RunnableLambda(lambda x: analyze_cons(x)) | model | StrOutputParser()\n",
    ")\n",
    "\n",
    "# Create the combined chain using LangChain Expression Language (LCEL)\n",
    "chain = (\n",
    "    prompt_template\n",
    "    | model\n",
    "    | StrOutputParser()\n",
    "    | RunnableParallel(branches={\"pros\": pros_branch_chain, \"cons\": cons_branch_chain})\n",
    "    | RunnableLambda(lambda x: combine_pros_cons(x[\"branches\"][\"pros\"], x[\"branches\"][\"cons\"]))\n",
    ")\n",
    "\n",
    "# Run the chain\n",
    "result = chain.invoke({\"product_name\": \"MacBook Pro\"})\n",
    "\n",
    "# Output\n",
    "print(result)\n"
   ],
   "id": "61dfc44335d19c86"
  }
 ],
 "metadata": {},
 "nbformat": 5,
 "nbformat_minor": 9
}
