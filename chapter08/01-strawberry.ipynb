{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AlexFly666/002-openai-quickstart-jike-peng/blob/main/openai_api/10-strawberry.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3150141f-f246-44e1-b6fe-43387d953783",
      "metadata": {
        "id": "3150141f-f246-44e1-b6fe-43387d953783"
      },
      "source": [
        "### 大模型不会计数\n",
        "尽管GPT和Claude等人工智能系统具有先进的能力，但它们在执行看似简单的任务时却举步维艰，例如计算某个字母在单词中出现的次数。\n",
        "\n",
        "例如，他们错误地指出字母“r”在单词“strawberry”中出现了两次。这似乎是一个微不足道的错误，但它表明了一个更大的事实：人工智能系统不像人类那样思考。它们没有大脑，也不像我们那样理解文本。"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# langchain+chatglm接口的使用\n",
        "# 安装 Langchain SDK\n",
        "!pip install langchain==0.3.14\\\n",
        "       langchain-openai==0.2.14\\\n",
        "       langchainhub==0.1.21"
      ],
      "metadata": {
        "collapsed": true,
        "id": "cwA4Y8CEZzU0",
        "outputId": "8a28cd93-6233-4e8c-a167-6afb09278935",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "cwA4Y8CEZzU0",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: langchain==0.3.14 in /usr/local/lib/python3.10/dist-packages (0.3.14)\n",
            "Collecting langchain-openai==0.2.14\n",
            "  Downloading langchain_openai-0.2.14-py3-none-any.whl.metadata (2.7 kB)\n",
            "Collecting langchainhub==0.1.21\n",
            "  Downloading langchainhub-0.1.21-py3-none-any.whl.metadata (659 bytes)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.10/dist-packages (from langchain==0.3.14) (6.0.2)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.10/dist-packages (from langchain==0.3.14) (2.0.36)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.10/dist-packages (from langchain==0.3.14) (3.11.11)\n",
            "Requirement already satisfied: async-timeout<5.0.0,>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from langchain==0.3.14) (4.0.3)\n",
            "Requirement already satisfied: langchain-core<0.4.0,>=0.3.29 in /usr/local/lib/python3.10/dist-packages (from langchain==0.3.14) (0.3.29)\n",
            "Requirement already satisfied: langchain-text-splitters<0.4.0,>=0.3.3 in /usr/local/lib/python3.10/dist-packages (from langchain==0.3.14) (0.3.5)\n",
            "Requirement already satisfied: langsmith<0.3,>=0.1.17 in /usr/local/lib/python3.10/dist-packages (from langchain==0.3.14) (0.2.10)\n",
            "Requirement already satisfied: numpy<2,>=1.22.4 in /usr/local/lib/python3.10/dist-packages (from langchain==0.3.14) (1.26.4)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in /usr/local/lib/python3.10/dist-packages (from langchain==0.3.14) (2.10.4)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.10/dist-packages (from langchain==0.3.14) (2.32.3)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10,>=8.1.0 in /usr/local/lib/python3.10/dist-packages (from langchain==0.3.14) (9.0.0)\n",
            "Requirement already satisfied: openai<2.0.0,>=1.58.1 in /usr/local/lib/python3.10/dist-packages (from langchain-openai==0.2.14) (1.59.4)\n",
            "Collecting tiktoken<1,>=0.7 (from langchain-openai==0.2.14)\n",
            "  Downloading tiktoken-0.8.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.6 kB)\n",
            "Requirement already satisfied: packaging<25,>=23.2 in /usr/local/lib/python3.10/dist-packages (from langchainhub==0.1.21) (24.2)\n",
            "Collecting types-requests<3.0.0.0,>=2.31.0.2 (from langchainhub==0.1.21)\n",
            "  Downloading types_requests-2.32.0.20241016-py3-none-any.whl.metadata (1.9 kB)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.3.14) (2.4.4)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.3.14) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.3.14) (24.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.3.14) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.3.14) (6.1.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.3.14) (0.2.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.3.14) (1.18.3)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.4.0,>=0.3.29->langchain==0.3.14) (1.33)\n",
            "Requirement already satisfied: typing-extensions>=4.7 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.4.0,>=0.3.29->langchain==0.3.14) (4.12.2)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from langsmith<0.3,>=0.1.17->langchain==0.3.14) (0.28.1)\n",
            "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.10/dist-packages (from langsmith<0.3,>=0.1.17->langchain==0.3.14) (3.10.13)\n",
            "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from langsmith<0.3,>=0.1.17->langchain==0.3.14) (1.0.0)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from openai<2.0.0,>=1.58.1->langchain-openai==0.2.14) (3.7.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.10/dist-packages (from openai<2.0.0,>=1.58.1->langchain-openai==0.2.14) (1.9.0)\n",
            "Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from openai<2.0.0,>=1.58.1->langchain-openai==0.2.14) (0.8.2)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from openai<2.0.0,>=1.58.1->langchain-openai==0.2.14) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.10/dist-packages (from openai<2.0.0,>=1.58.1->langchain-openai==0.2.14) (4.67.1)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain==0.3.14) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.27.2 in /usr/local/lib/python3.10/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain==0.3.14) (2.27.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain==0.3.14) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain==0.3.14) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain==0.3.14) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain==0.3.14) (2024.12.14)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from SQLAlchemy<3,>=1.4->langchain==0.3.14) (3.1.1)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.10/dist-packages (from tiktoken<1,>=0.7->langchain-openai==0.2.14) (2024.11.6)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai<2.0.0,>=1.58.1->langchain-openai==0.2.14) (1.2.2)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->langsmith<0.3,>=0.1.17->langchain==0.3.14) (1.0.7)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<0.3,>=0.1.17->langchain==0.3.14) (0.14.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.10/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.4.0,>=0.3.29->langchain==0.3.14) (3.0.0)\n",
            "Downloading langchain_openai-0.2.14-py3-none-any.whl (50 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.9/50.9 kB\u001b[0m \u001b[31m3.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading langchainhub-0.1.21-py3-none-any.whl (5.2 kB)\n",
            "Downloading tiktoken-0.8.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m36.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading types_requests-2.32.0.20241016-py3-none-any.whl (15 kB)\n",
            "Installing collected packages: types-requests, tiktoken, langchainhub, langchain-openai\n",
            "Successfully installed langchain-openai-0.2.14 langchainhub-0.1.21 tiktoken-0.8.0 types-requests-2.32.0.20241016\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from langchain_openai import ChatOpenAI\n",
        "from langchain.prompts import (\n",
        "    ChatPromptTemplate,\n",
        "    MessagesPlaceholder,\n",
        "    SystemMessagePromptTemplate,\n",
        "    HumanMessagePromptTemplate,\n",
        ")\n",
        "from langchain.chains import LLMChain\n",
        "from langchain.memory import ConversationBufferMemory\n",
        "\n",
        "\n",
        "# Initialize the ChatOpenAI model\n",
        "llm = ChatOpenAI(\n",
        "    temperature=0.95,\n",
        "    model=\"gpt-3.5-turbo-instruct\",\n",
        "    openai_api_key=\"XXXX\",\n",
        "    openai_api_base=\"https://vip.apiyi.com/v1\"\n",
        ")\n",
        "\n",
        "# First interaction (without Chain of Thought)\n",
        "messages = [\n",
        "    (\"human\", \"Count the occurrences of the letter 'r' in the word 'strawberry'.\"),\n",
        "]\n",
        "\n",
        "print(\"gpt-3.5-turbo\")\n",
        "ai_msg = llm.invoke(messages)\n",
        "print(ai_msg.content)  # prints the response\n",
        "\n",
        "print(\"------------\")\n",
        "\n",
        "# Second interaction (with Chain of Thought)\n",
        "messages = [\n",
        "    (\n",
        "    \"system\",\n",
        "    \"\"\"\n",
        "    <chain of thought>\n",
        "\n",
        "    EXAMPLE: Count the occurrences of the letter 'p' in the word 'apple'.\n",
        "    To determine the number of occurrences of the letter 'p' in the word 'apple', we scan through the word letter by letter:\n",
        "\n",
        "    'a' (0), 'p' (1), 'p' (2), 'l' (0), 'e' (0).\n",
        "\n",
        "    Therefore, the letter 'p' appears 2 times.\n",
        "\n",
        "    </chain of thought>\n",
        "\n",
        "    IMPORTANT! USE ABOVE CHAIN OF THOUGHT TO GENERATE YOUR RESPONSE!\n",
        "    \"\"\",\n",
        "    ),\n",
        "    (\"human\", \"Count the occurrences of the letter 'r' in the word 'strawberry'.\"),\n",
        "]\n",
        "ai_msg = llm.invoke(messages)\n",
        "ai_msg\n",
        "\n",
        "print(\"gpt-3.5-turbo with CoT\")\n",
        "print(ai_msg.content)  # prints the response with chain of thought\n",
        "\n",
        "print(\"------------\")\n"
      ],
      "metadata": {
        "id": "Kzmf1iXrW_O7",
        "outputId": "00b39f45-2f33-477e-a329-f07d033e09cb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "Kzmf1iXrW_O7",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "gpt-3.5-turbo\n",
            "The letter 'r' occurs 2 times in the word 'strawberry'.\n",
            "------------\n",
            "gpt-3.5-turbo with CoT\n",
            "To determine the number of occurrences of the letter 'r' in the word 'strawberry', we scan through the word letter by letter:\n",
            "\n",
            "'s' (0), 't' (0), 'r' (1), 'a' (0), 'w' (0), 'b' (0), 'e' (0), 'r' (2), 'r' (3), 'y' (0).\n",
            "\n",
            "Therefore, the letter 'r' appears 3 times.\n",
            "------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 导入必要的库\n",
        "import os  # 用于与操作系统交互，例如管理环境变量或文件路径\n",
        "from langchain_openai import ChatOpenAI  # 用于与 OpenAI 的聊天模型交互，例如 GPT-3.5 Turbo\n",
        "from langchain.prompts import (\n",
        "    ChatPromptTemplate,  # 用于创建聊天提示模板\n",
        "    MessagesPlaceholder,  # 用于在提示中插入消息\n",
        "    SystemMessagePromptTemplate,  # 用于创建系统消息提示模板\n",
        "    HumanMessagePromptTemplate,  # 用于创建用户消息提示模板\n",
        ")\n",
        "from langchain.chains import LLMChain  # 用于创建调用语言模型和其他实用程序的链\n",
        "from langchain.memory import ConversationBufferMemory  # 用于存储和管理用户与语言模型之间的对话历史\n",
        "\n",
        "\n",
        "# 初始化 ChatOpenAI 模型\n",
        "llm = ChatOpenAI(\n",
        "    temperature=0.95,  # 控制模型输出的随机性，值越高，输出越有创意和不可预测\n",
        "    model=\"gpt-3.5-turbo-instruct\",  # 指定要使用的 OpenAI 模型\n",
        "    openai_api_key=\"XXXX\",  # 提供访问 OpenAI API 所需的 API 密钥\n",
        "    openai_api_base=\"https://vip.apiyi.com/v1\"  # 指定 OpenAI API 的基本 URL，可能用于代理或其他服务提供商\n",
        ")\n",
        "\n",
        "# 第一次交互（没有思维链）\n",
        "messages = [\n",
        "    (\"human\", \"Count the occurrences of the letter 'r' in the word 'strawberry'.\"),  # 用户消息：计算单词 \"strawberry\" 中字母 \"r\" 的出现次数\n",
        "]\n",
        "\n",
        "print(\"gpt-3.5-turbo\")  # 打印模型名称\n",
        "ai_msg = llm.invoke(messages)  # 调用语言模型并获取响应\n",
        "print(ai_msg.content)  # 打印模型的响应内容\n",
        "\n",
        "print(\"------------\")  # 分隔符\n",
        "\n",
        "# 第二次交互（使用思维链）\n",
        "messages = [\n",
        "    (\n",
        "    \"system\",  # 系统消息，用于提供思维链提示\n",
        "    \"\"\"\n",
        "    <chain of thought>  # 思维链开始\n",
        "\n",
        "    EXAMPLE: Count the occurrences of the letter 'p' in the word 'apple'.  # 示例：计算单词 \"apple\" 中字母 \"p\" 的出现次数\n",
        "    To determine the number of occurrences of the letter 'p' in the word 'apple', we scan through the word letter by letter:  # 确定字母 \"p\" 在单词 \"apple\" 中出现次数的方法\n",
        "    'a' (0), 'p' (1), 'p' (2), 'l' (0), 'e' (0).  # 扫描单词 \"apple\" 中的每个字母并计数\n",
        "    Therefore, the letter 'p' appears 2 times.  # 因此，字母 \"p\" 出现了 2 次\n",
        "\n",
        "\n",
        "    </chain of thought>  # 思维链结束\n",
        "\n",
        "    IMPORTANT! USE ABOVE CHAIN OF THOUGHT TO GENERATE YOUR RESPONSE!  # 重要提示：使用上述思维链生成你的响应！\n",
        "    \"\"\",\n",
        "    ),\n",
        "    (\"human\", \"Count the occurrences of the letter 'r' in the word 'strawberry'.\"),  # 用户消息：计算单词 \"strawberry\" 中字母 \"r\" 的出现次数\n",
        "]\n",
        "ai_msg = llm.invoke(messages)  # 调用语言模型并获取响应\n",
        "ai_msg\n",
        "\n",
        "print(\"gpt-3.5-turbo with CoT\")  # 打印模型名称和提示类型\n",
        "print(ai_msg.content)  # 打印模型的响应内容\n",
        "\n",
        "print(\"------------\")  # 分隔符"
      ],
      "metadata": {
        "id": "xPHjJQIMkTiN",
        "outputId": "f222d505-5974-4668-a4d8-3cd70d6e030f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "xPHjJQIMkTiN",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "gpt-3.5-turbo\n",
            "The letter 'r' occurs 2 times in the word 'strawberry'.\n",
            "------------\n",
            "gpt-3.5-turbo with CoT\n",
            "To determine the number of occurrences of the letter 'r' in the word 'strawberry', we scan through the word letter by letter:\n",
            "\n",
            "- 's' (0)\n",
            "- 't' (0)\n",
            "- 'r' (1)\n",
            "- 'a' (0)\n",
            "- 'w' (0)\n",
            "- 'b' (0)\n",
            "- 'e' (0)\n",
            "- 'r' (2)\n",
            "- 'r' (3)\n",
            "- 'y' (0)\n",
            "\n",
            "Therefore, the letter 'r' appears 3 times in the word 'strawberry'.\n",
            "------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Qs5SOfXsZyRZ"
      },
      "id": "Qs5SOfXsZyRZ",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.14"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}